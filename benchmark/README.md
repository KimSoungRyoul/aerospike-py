# Benchmark: aerospike-py vs Official aerospike (C Client)

Measures how aerospike-py (Rust/PyO3) compares to the official aerospike Python client (C extension).

## Methodology

For consistent, reproducible results:

1. **Warmup** (default 200 ops) — stabilizes connection pools and server cache before measuring
2. **Multiple rounds** (default 5) — reports median-of-medians across rounds
3. **Data separation** — read benchmarks use pre-seeded data; put is measured independently
4. **GC disabled** — Python garbage collection is off during measurement intervals
5. **Key isolation** — each client uses a unique key prefix to avoid interference

## Comparison Targets

| Column | Client | Description |
| ------ | ------ | ----------- |
| aerospike-py (Rust) | `aerospike.Client` | Rust-based sync client |
| official aerospike (C) | `aerospike.client` (PyPI) | Official C extension sync client |
| aerospike-py async (Rust) | `aerospike.AsyncClient` | Rust-based async client + `asyncio.gather` |

## Prerequisites

```bash
# Aerospike server
docker run -d --name aerospike \
  -p 3000:3000 \
  -e "NAMESPACE=test" \
  -e "CLUSTER_NAME=docker" \
  aerospike/aerospike-server

# Install both clients
maturin develop              # aerospike-py (Rust)
pip install aerospike        # official C client
```

## Run

```bash
# Default (1000 ops x 5 rounds, concurrency 50)
bash benchmark/run_all.sh

# Custom: count rounds concurrency
bash benchmark/run_all.sh 2000 7 100

# Direct execution
python benchmark/bench_compare.py --count 1000 --rounds 5 --warmup 200 --concurrency 50
```

## Output

```text
Benchmark config:
  ops/round  = 1,000
  rounds     = 5
  warmup     = 200
  concurrency= 50

====================================================================================================
  aerospike-py Benchmark  (1,000 ops x 5 rounds, warmup=200, async concurrency=50)
====================================================================================================

  Avg Latency (ms)  —  lower is better  [median of round means]
  ──────────────────────────────────────────────────────────────────────────────
  Operation    |   aerospike-py (Rust) | official aerospike (C) |   aerospike-py async |     Rust vs C |    Async vs C
  put          |              0.310ms  |               0.580ms  |              0.041ms | 1.9x faster   | 14.1x faster
  get          |              0.195ms  |               0.398ms  |              0.028ms | 2.0x faster   | 14.2x faster
  batch_get    |              0.044ms  |               0.088ms  |              0.031ms | 2.0x faster   |  2.8x faster
  scan         |              0.011ms  |               0.030ms  |              0.009ms | 2.7x faster   |  3.3x faster

  Stability (stdev of round median latency, ms)  —  lower = more stable
  ──────────────────────────────────────────────────────────────────────────────
  Operation    |            Rust stdev |              C stdev  |         Async stdev
  put          |              0.008ms  |              0.015ms  |              0.003ms
  get          |              0.005ms  |              0.012ms  |              0.002ms
```

## Metrics

| Metric | Description |
| ------ | ----------- |
| avg_ms | Median of round means (lower is better) |
| p50_ms | Median of round medians |
| p99_ms | Aggregated 99th percentile |
| ops_per_sec | Median of round throughputs (higher is better) |
| stdev_ms | Stdev of round medians (lower = more stable) |
| Rust vs C | Speedup of aerospike-py sync vs C client |
| Async vs C | Speedup of aerospike-py async vs C client |

## Environment Variables

| Variable | Default | Description |
| -------- | ------- | ----------- |
| `AEROSPIKE_HOST` | `127.0.0.1` | Aerospike host |
| `AEROSPIKE_PORT` | `3000` | Aerospike port |

## Why Faster?

- **Rust async runtime**: Tokio-based async I/O under the hood
- **Zero-copy**: Efficient Python-Rust type conversion via PyO3
- **Native async**: `AsyncClient` + `asyncio.gather` for thousands of concurrent requests
- **No GIL bottleneck**: GIL released during Rust execution (`py.allow_threads`)
